{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtvIbg8XWrTs"
   },
   "source": [
    "# Training sample (Notebook/Google Colaboratory version)\n",
    "\n",
    "この Notebook は [Ultralytics](https://github.com/ultralytics/ultralytics) と Google Colaboratory を用いて YOLO11 物体検出モデルを学習するサンプルです。  \n",
    "\n",
    "Notebook を用いずに学習を行なう場合は、 [`train.py`](./train.py) を用いてください。\n",
    "\n",
    "また、 [`README.md`](./README.md) を参照し、データセットの配置を行なってください。\n",
    "\n",
    "このサンプルでは、Google Driveに作業フォルダーとデータセットのzipファイルを次の形で配置したものとして説明をしております。\n",
    "```\n",
    "AI_Contest\n",
    "└── dataset.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7ajWL4_L-1_"
   },
   "source": [
    "⚠ データセットおよびワークフォルダーの配置が上記と異なる場合は `DATASET_ROOT` 、 `DATASET_ARCHIVE_FILE` を正しいパスへ変更してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e1iv0gGXd_X"
   },
   "source": [
    "# Step 1 - ライブラリのインストールとGoogleDriveへの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oe4VnTv5WUDX"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch (The content might change depending on the runtime).\n",
    "!pip install torch torchvision\n",
    "# Install necessary dependencies.\n",
    "!pip install tqdm ultralytics\n",
    "# Additional library for notebook.\n",
    "!pip install ipywidgets\n",
    "\n",
    "# Mount Google Drive personal space.\n",
    "# When executing this cell, an access request window will pop-up.\n",
    "# Please login and grant the necessary permissions.\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dt0sDkP4YyUu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "DRIVE_DIR = \"AI_Contest/\"\n",
    "WORK_DRIVE_DIR = os.path.join(\"/content/drive/MyDrive/\", DRIVE_DIR)\n",
    "DATASET_ARCHIVE_FILE = os.path.join(WORK_DRIVE_DIR, \"dataset.zip\")\n",
    "WORK_DIR = \"/content\"\n",
    "DATASET_ROOT = os.path.join(WORK_DIR, \"dataset\")\n",
    "DATASET_SAVE_DIR = os.path.join(WORK_DIR, \"ultralytics_dataset\")\n",
    "TRAINING_SAVE_DIR = os.path.join(WORK_DRIVE_DIR, \"outputs\")\n",
    "\n",
    "if os.path.exists(DATASET_SAVE_DIR):\n",
    "    rmtree(DATASET_SAVE_DIR)\n",
    "\n",
    "if not os.path.exists(DATASET_ARCHIVE_FILE):\n",
    "    print(f\"[ERROR] Cannot find the dataset {DATASET_ARCHIVE_FILE}\")\n",
    "\n",
    "! cd \"{WORK_DIR}\" && unzip \"{DATASET_ARCHIVE_FILE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4nQLGalbNda"
   },
   "source": [
    "## Step 1 - データセットの準備\n",
    "\n",
    "ここでは 配布しているCOCO形式のデータセットを Ultralytics で利用可能な形式へ変換します。  \n",
    "\n",
    "この手順は次の処理を行ないます。\n",
    "\n",
    "1. annotation ファイルを変換\n",
    "2. 画像を再配置\n",
    "3. 学習用データを学習用と評価用へ分離(val.jsonが存在しない場合のみ)\n",
    "4. 学習に用いる設定ファイル(YAML)を作成\n",
    "\n",
    "なお、このスクリプトはCOCO形式のデータセットに学習用(train.json)、評価用(val.json)、テスト用(test.json)のそれぞれに対してUltralytics向けへ変換を行います。  \n",
    "また、val.jsonが存在しない場合の学習用データと評価用データ分離の比率は `TRAIN_SPLIT` で制御が可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1dUhZTlbPxf"
   },
   "source": [
    "### Step 1.1 - Annotation ファイルの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFeYWYtibN3A"
   },
   "outputs": [],
   "source": [
    "from ultralytics.data.converter import convert_coco\n",
    "\n",
    "def prepare_annotations(src_annotations_path: str, dst_path: str):\n",
    "    \"\"\"Converts annotations in Ultralytics' format (YOLO).\"\"\"\n",
    "    # cf. https://docs.ultralytics.com/reference/data/converter/#ultralytics.data.converter.convert_coco\n",
    "    convert_coco(\n",
    "        labels_dir=src_annotations_path,\n",
    "        save_dir=dst_path,\n",
    "        cls91to80=False\n",
    "    )\n",
    "    print(f\"Annotations saved to {os.path.join(dst_path, 'labels')}\")\n",
    "\n",
    "src_annotations_path = os.path.join(DATASET_ROOT, \"annotations\")\n",
    "prepare_annotations(src_annotations_path, DATASET_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJshrKrWbiQe"
   },
   "source": [
    "### Step 1.2 - 画像ファイルの再配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BC323Z8IbioW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "LABELS = (\"train\", \"val\", \"test\")\n",
    "\n",
    "def load_json(json_path: str) -> dict:\n",
    "    \"\"\" Loads a JSON file from disk.\"\"\"\n",
    "    with open(json_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def copy_images(\n",
    "    image_filenames: list,\n",
    "    src_images_path: str,\n",
    "    dst_images_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates symbolic links of a list of images from a source directory\n",
    "    into a destination directory.\n",
    "    \"\"\"\n",
    "    for filename in tqdm(image_filenames):\n",
    "        src_file = os.path.join(src_images_path, filename)\n",
    "        dst_file = os.path.join(dst_images_path, filename)\n",
    "\n",
    "        if os.path.isfile(src_file):  # Only copy files, ignore directories.\n",
    "            # Create symbolic link to reduce disk memory usage.\n",
    "            os.symlink(src_file, dst_file)\n",
    "\n",
    "def prepare_images(\n",
    "    src_annotations_path: str,\n",
    "    src_images_path: str,\n",
    "    dst_path: str\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Organizes images in Ultralytics' format and returns from the annotations\n",
    "    the list of object categories (classes) to detect.\n",
    "    \"\"\"\n",
    "    categories = []\n",
    "\n",
    "    # Copy images into correct folder\n",
    "    for label in LABELS:\n",
    "        src_annotations_path_with_label = os.path.join(\n",
    "            src_annotations_path,\n",
    "            f\"{label}.json\"\n",
    "        )\n",
    "\n",
    "        # Skip non-existant labels\n",
    "        if not os.path.exists(src_annotations_path_with_label):\n",
    "            print(f\"[WARNING] No {label} data found.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing '{label}' images...\")\n",
    "        dst_images_path = os.path.join(dst_path, \"images\", label)\n",
    "        os.makedirs(dst_images_path, exist_ok=True)\n",
    "\n",
    "        # Get list of images to copy\n",
    "        json_data = load_json(src_annotations_path_with_label)\n",
    "        image_filenames = [img[\"file_name\"] for img in json_data[\"images\"]]\n",
    "\n",
    "        copy_images(image_filenames, src_images_path, dst_images_path)\n",
    "\n",
    "        # Get detection categories\n",
    "        if len(categories) == 0:\n",
    "            categories = json_data.get(\"categories\", [])\n",
    "\n",
    "    print(f\"Images saved to {os.path.join(dst_path, 'images')}\")\n",
    "    return categories\n",
    "\n",
    "src_images_path = os.path.join(DATASET_ROOT, \"images\")\n",
    "\n",
    "categories = prepare_images(src_annotations_path, src_images_path, DATASET_SAVE_DIR)\n",
    "\n",
    "if len(categories) == 0:\n",
    "    print(\"[WARNING] No detection categories (classes) could be loaded from the annotation files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3 - 学習用データを学習用と評価用へ分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "def split_train_to_train_and_val(dst_path: str):\n",
    "    train_image_path = os.path.join(dst_path, \"images\", \"train\")\n",
    "    val_image_path = os.path.join(dst_path, \"images\", \"val\")\n",
    "    train_label_path = os.path.join(dst_path, \"labels\", \"train\")\n",
    "    val_label_path = os.path.join(dst_path, \"labels\", \"val\")\n",
    "    os.makedirs(val_image_path)\n",
    "    os.makedirs(val_label_path)\n",
    "    files = list(glob.glob(os.path.join(train_image_path, \"*\")))\n",
    "    for file in files[int(len(files) * TRAIN_SPLIT):]:\n",
    "        image_file = os.path.basename(file)\n",
    "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "        os.rename(os.path.join(train_image_path, image_file), os.path.join(val_image_path, image_file))\n",
    "        os.rename(os.path.join(train_label_path, label_file), os.path.join(val_label_path, label_file))\n",
    "\n",
    "# Generate validation dataset if val.json does not exist.\n",
    "if not os.path.exists(os.path.join(src_annotations_path, \"val.json\")):\n",
    "    print(\"[INFO] Generate validation dataset from train dataset\")\n",
    "    split_train_to_train_and_val(DATASET_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0tA3RXObqGb"
   },
   "source": [
    "### Step 1.4 - 設定ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5TRpvBdbrzZ"
   },
   "outputs": [],
   "source": [
    "def prepare_configuration_file(categories, dst_path) -> str:\n",
    "    \"\"\"Creates Ultralytics' configuration file.\"\"\"\n",
    "    # COCO IDs start from 1 but Ultralytics' start from 0.\n",
    "    dict_categories = {cat[\"id\"] - 1: cat[\"name\"] for cat in categories}\n",
    "\n",
    "    # Create YAML configuration file.\n",
    "    yaml_file_path = os.path.join(dst_path, \"data.yaml\")\n",
    "    with open(yaml_file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"path: {os.path.abspath(dst_path)}  # dataset root dir\\n\")\n",
    "        f.write(\"train: images/train  # train images (relative to 'path')\\n\")\n",
    "        f.write(\"val: images/val  # val images (relative to 'path')\\n\")\n",
    "        f.write(\"test: images/test  # test images (optional)\\n\\n\")\n",
    "\n",
    "        f.write(\"# Classes\\n\")\n",
    "        f.write(\"names:\\n\")\n",
    "        for cat_id in sorted(dict_categories.keys()):\n",
    "            f.write(f\"    {cat_id}: {dict_categories[cat_id]}\\n\")\n",
    "\n",
    "    print(f\"Configuration saved to {yaml_file_path}\")\n",
    "    return yaml_file_path\n",
    "\n",
    "yaml_conf_path = prepare_configuration_file(categories, DATASET_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGOrXTSjbvfC"
   },
   "source": [
    "## Step 2 - 学習\n",
    "\n",
    "変換したデータセットを用いて YOLO 11 nano　を学習します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEjy9eBobxee"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "# Load a pretrained YOLO11 model.\n",
    "pretrained_model_path = \"/content/weights/yolo11n.pt\"\n",
    "model = YOLO(pretrained_model_path)\n",
    "print(model)\n",
    "\n",
    "\n",
    "DEVICE = [0,] if torch.cuda.is_available() else \"cpu\"\n",
    "N_EPOCHS = 50\n",
    "IMAGE_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Train the model.\n",
    "# cf. https://docs.ultralytics.com/modes/train/#train-settings\n",
    "model.train(\n",
    "    data=yaml_conf_path,\n",
    "    project=TRAINING_SAVE_DIR,\n",
    "    name=datetime.now().strftime(\"train_%Y-%m-%d_%H-%M-%S\"),\n",
    "    pretrained=True,\n",
    "    epochs=N_EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が完了すると、学習済みモデル (`outputs/train_YYYY-MM-DD_HH-MM-SS/weights/best.pt`) がGoogle Driveの作業用フォルダーへ保存されます"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
