{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439b0ac0",
   "metadata": {},
   "source": [
    "# Training sample (Notebook version)\n",
    "\n",
    "この Notebook は　[Ultralytics](https://github.com/ultralytics/ultralytics) を用いて YOLO11 物体検出モデルを学習するサンプルです。\n",
    "\n",
    "Notebook を用いずに学習を行なう場合は、 [`train.py`](./train.py) を用いてください。\n",
    "\n",
    "また、 [`README.md`](./README.md) を参照し、環境設定とデータセットの展開を行なってください。  \n",
    "\n",
    "このサンプルでは、サンプルスクリプトと同じ場所に、配布されているデータセット `dataset.zip` を展開したものとして説明をしております。\n",
    "```bash\n",
    "├── train.ipynb\n",
    "└── dataset/\n",
    "    ├── annotations/\n",
    "    │   └── train.json\n",
    "    └── images/\n",
    "        ├── T1.jpg\n",
    "        ├── T2.jpg\n",
    "        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3ec90-efb0-4ab2-b584-77b28669e6bf",
   "metadata": {},
   "source": [
    "⚠ データセットの展開場所が上記と異なる場合は `DATASET_ROOT` を正しいパスへ変更してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b7586-e830-4adf-b96f-140187474a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "\n",
    "DATASET_ROOT = \"./dataset\"\n",
    "DATASET_SAVE_DIR = \"./ultralytics_dataset\"\n",
    "TRAINING_SAVE_DIR = \"./outputs\"\n",
    "\n",
    "if os.path.exists(DATASET_SAVE_DIR):\n",
    "    rmtree(DATASET_SAVE_DIR)\n",
    "\n",
    "if not os.path.exists(DATASET_ROOT):\n",
    "    print(f\"[ERROR] Cannot find the dataset {DATASET_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138af22-f872-40df-94e8-f7c7577f622e",
   "metadata": {},
   "source": [
    "## Step 1 - データセットの準備\n",
    "\n",
    "ここでは 配布しているCOCO形式のデータセットを Ultralytics で利用可能な形式へ変換します。  \n",
    "\n",
    "この手順は次の処理を行ないます。\n",
    "\n",
    "1. annotation ファイルを変換\n",
    "2. 画像を再配置\n",
    "3. 学習用データを学習用と評価用へ分離(val.jsonが存在しない場合のみ)\n",
    "4. 学習に用いる設定ファイル(YAML)を作成\n",
    "\n",
    "なお、このスクリプトはCOCO形式のデータセットに学習用(train.json)、評価用(val.json)、テスト用(test.json)のそれぞれに対してUltralytics向けへ変換を行います。  \n",
    "また、val.jsonが存在しない場合の学習用データと評価用データ分離の比率は `TRAIN_SPLIT` で制御が可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c7b13-5418-4184-b406-0f7c9b004529",
   "metadata": {},
   "source": [
    "### Step 1.1 - Annotation ファイルの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c44597-b436-4c6a-aac5-a0e223f3ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.converter import convert_coco\n",
    "\n",
    "def prepare_annotations(src_annotations_path: str, dst_path: str):\n",
    "    \"\"\"Converts annotations in Ultralytics' format (YOLO).\"\"\"\n",
    "    # cf. https://docs.ultralytics.com/reference/data/converter/#ultralytics.data.converter.convert_coco\n",
    "    convert_coco(\n",
    "        labels_dir=src_annotations_path,\n",
    "        save_dir=dst_path,\n",
    "        cls91to80=False\n",
    "    )\n",
    "    print(f\"Annotations saved to {os.path.join(dst_path, 'labels')}\")\n",
    "\n",
    "src_annotations_path = os.path.join(DATASET_ROOT, \"annotations\")\n",
    "prepare_annotations(src_annotations_path, DATASET_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e16c70-8223-4ccc-a61e-7d2646390741",
   "metadata": {},
   "source": [
    "### Step 1.2 - 画像ファイルの再配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82849d-43ed-4cb5-9e74-37c5055e033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys \n",
    "from tqdm import tqdm\n",
    "from shutil import copy\n",
    "\n",
    "LABELS = (\"train\", \"val\", \"test\")\n",
    "\n",
    "def load_json(json_path: str) -> dict:\n",
    "    \"\"\" Loads a JSON file from disk.\"\"\"\n",
    "    with open(json_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def copy_images(\n",
    "    image_filenames: list,\n",
    "    src_images_path: str,\n",
    "    dst_images_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates symbolic links of a list of images from a source directory\n",
    "    into a destination directory.\n",
    "    \"\"\"\n",
    "    for filename in tqdm(image_filenames):\n",
    "        src_file = os.path.abspath(os.path.join(src_images_path, filename))\n",
    "        dst_file = os.path.abspath(os.path.join(dst_images_path, filename))\n",
    "\n",
    "        if os.path.isfile(src_file):  \n",
    "            # Only copy files, ignore directories.\n",
    "            if sys.platform == \"win32\":\n",
    "                # Windows does not support symlink\n",
    "                copy(src_file, dst_file)\n",
    "            else:\n",
    "                # Create symbolic link to reduce disk memory usage.\n",
    "                os.symlink(src_file, dst_file)\n",
    "\n",
    "def prepare_images(\n",
    "    src_annotations_path: str,\n",
    "    src_images_path: str,\n",
    "    dst_path: str\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Organizes images in Ultralytics' format and returns from the annotations\n",
    "    the list of object categories (classes) to detect.\n",
    "    \"\"\"\n",
    "    categories = []\n",
    "\n",
    "    # Copy images into correct folder\n",
    "    for label in LABELS:\n",
    "        src_annotations_path_with_label = os.path.join(\n",
    "            src_annotations_path,\n",
    "            f\"{label}.json\"\n",
    "        )\n",
    "\n",
    "        # Skip non-existant labels\n",
    "        if not os.path.exists(src_annotations_path_with_label):\n",
    "            print(f\"[WARNING] No {label} data found.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing '{label}' images...\")\n",
    "        dst_images_path = os.path.join(dst_path, \"images\", label)\n",
    "        os.makedirs(dst_images_path, exist_ok=True)\n",
    "\n",
    "        # Get list of images to copy\n",
    "        json_data = load_json(src_annotations_path_with_label)\n",
    "        image_filenames = [img[\"file_name\"] for img in json_data[\"images\"]]\n",
    "\n",
    "        copy_images(image_filenames, src_images_path, dst_images_path)\n",
    "\n",
    "        # Get detection categories\n",
    "        if len(categories) == 0:\n",
    "            categories = json_data.get(\"categories\", [])\n",
    "\n",
    "    print(f\"Images saved to {os.path.join(dst_path, 'images')}\")\n",
    "    return categories\n",
    "\n",
    "src_images_path = os.path.join(DATASET_ROOT, \"images\")\n",
    "\n",
    "categories = prepare_images(src_annotations_path, src_images_path, DATASET_SAVE_DIR)\n",
    "\n",
    "if len(categories) == 0:\n",
    "    print(\"[WARNING] No detection categories (classes) could be loaded from the annotation files.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe4adb",
   "metadata": {},
   "source": [
    "### Step 1.3 - 学習用データを学習用と評価用へ分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "def split_train_to_train_and_val(dst_path: str):\n",
    "    train_image_path = os.path.join(dst_path, \"images\", \"train\")\n",
    "    val_image_path = os.path.join(dst_path, \"images\", \"val\")\n",
    "    train_label_path = os.path.join(dst_path, \"labels\", \"train\")\n",
    "    val_label_path = os.path.join(dst_path, \"labels\", \"val\")\n",
    "    os.makedirs(val_image_path)\n",
    "    os.makedirs(val_label_path)\n",
    "    files = list(glob.glob(os.path.join(train_image_path, \"*\")))\n",
    "    for file in files[int(len(files) * TRAIN_SPLIT):]:\n",
    "        image_file = os.path.basename(file)\n",
    "        label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "        os.rename(os.path.join(train_image_path, image_file), os.path.join(val_image_path, image_file))\n",
    "        os.rename(os.path.join(train_label_path, label_file), os.path.join(val_label_path, label_file))\n",
    "\n",
    "# Generate validation dataset if val.json does not exist.\n",
    "if not os.path.exists(os.path.join(src_annotations_path, \"val.json\")):\n",
    "    print(\"[INFO] Generate validation dataset from train dataset\")\n",
    "    split_train_to_train_and_val(DATASET_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4784e1-54fe-4099-a8cc-f2e545d55b4f",
   "metadata": {},
   "source": [
    "### Step 1.4 - 設定ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bc647-1c58-49c7-a978-29b6bf6a51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_configuration_file(categories, dst_path) -> str:\n",
    "    \"\"\"Creates Ultralytics' configuration file.\"\"\"\n",
    "    # COCO IDs start from 1 but Ultralytics' start from 0.\n",
    "    dict_categories = {cat[\"id\"] - 1: cat[\"name\"] for cat in categories}\n",
    "\n",
    "    # Create YAML configuration file.\n",
    "    yaml_file_path = os.path.join(dst_path, \"data.yaml\")\n",
    "    with open(yaml_file_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"path: {os.path.abspath(dst_path)}  # dataset root dir\\n\")\n",
    "        f.write(\"train: images/train  # train images (relative to 'path')\\n\")\n",
    "        f.write(\"val: images/val  # val images (relative to 'path')\\n\")\n",
    "        f.write(\"test: images/test  # test images (optional)\\n\\n\")\n",
    "\n",
    "        f.write(\"# Classes\\n\")\n",
    "        f.write(\"names:\\n\")\n",
    "        for cat_id in sorted(dict_categories.keys()):\n",
    "            f.write(f\"    {cat_id}: {dict_categories[cat_id]}\\n\")\n",
    "\n",
    "    print(f\"Configuration saved to {yaml_file_path}\")\n",
    "    return yaml_file_path\n",
    "\n",
    "yaml_conf_path = prepare_configuration_file(categories, DATASET_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0373ab-a38b-4046-97f6-437205606276",
   "metadata": {},
   "source": [
    "## Step 2 - 学習\n",
    "\n",
    "変換したデータセットを用いて YOLO 11 nano　を学習します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a0ffd-3fb8-450e-8907-7660157e9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "DEVICE = [0,] if torch.cuda.is_available() else \"cpu\"\n",
    "N_EPOCHS = 50\n",
    "IMAGE_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Load a pretrained YOLO11 model.\n",
    "pretrained_model_path = \"./weights/yolo11n.pt\"\n",
    "model = YOLO(pretrained_model_path)\n",
    "print(model)\n",
    "\n",
    "# Train the model.\n",
    "# cf. https://docs.ultralytics.com/modes/train/#train-settings\n",
    "model.train(\n",
    "    data=yaml_conf_path,\n",
    "    project=TRAINING_SAVE_DIR,\n",
    "    name=datetime.now().strftime(\"train_%Y-%m-%d_%H-%M-%S\"),\n",
    "    pretrained=True,\n",
    "    epochs=N_EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229b61d",
   "metadata": {},
   "source": [
    "学習が完了すると、学習済みモデル (`outputs/train_YYYY-MM-DD_HH-MM-SS/weights/best.pt`) がサンプルコード (`train.ipynb`) と同じ場所へ生成されます"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
